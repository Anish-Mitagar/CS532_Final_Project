{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StringIndexer took 0.16299279 seconds\n",
      "OneHotEncoder took 0.01275621 seconds\n",
      "StringIndexer took 0.16026562 seconds\n",
      "OneHotEncoder took 0.01435787 seconds\n",
      "VectorAssembler took 0.00701771 seconds\n",
      "StandardScaler took 0.23438192 seconds\n",
      "VectorAssembler took 0.00585433 seconds\n",
      "CrossValidator took 10.16833188 seconds\n",
      "Test set accuracy = 0.97071\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"DiabetesPredictionPipeline\").getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"diabetes_prediction_dataset.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Columns for features and label\n",
    "numerical_features = ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "categorical_features = ['gender', 'smoking_history']\n",
    "label_col = 'diabetes'\n",
    "\n",
    "# Stages\n",
    "stages = []\n",
    "stage_times = []\n",
    "\n",
    "# Data Preprocessing for Numerical Features\n",
    "num_assembler = VectorAssembler(inputCols=numerical_features, outputCol=\"num_features\")\n",
    "scaler = StandardScaler(inputCol=\"num_features\", outputCol=\"scaled_num_features\")\n",
    "\n",
    "# Data Preprocessing for Categorical Features\n",
    "for categoricalCol in categorical_features:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "# Combine all processed numerical and categorical features into a single feature vector\n",
    "assembler_inputs = [c + \"classVec\" for c in categorical_features] + [\"scaled_num_features\"]\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "stages += [num_assembler, scaler, assembler]\n",
    "\n",
    "\n",
    "\n",
    "# Apply each stage manually and time them\n",
    "for stage in stages:\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # For estimators (like StringIndexer, OneHotEncoder, and StandardScaler), fit and then transform\n",
    "    if isinstance(stage, StringIndexer) or isinstance(stage, OneHotEncoder) or isinstance(stage, StandardScaler):\n",
    "        model = stage.fit(df)\n",
    "        df = model.transform(df)\n",
    "    else:  # For transformers (like VectorAssembler), just transform\n",
    "        df = stage.transform(df)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    stage_times.append((stage.__class__.__name__, end_time - start_time))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=label_col, featuresCol=\"features\")\n",
    "\n",
    "# Now apply CrossValidator\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .addGrid(rf.maxDepth, [5]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\"),\n",
    "                          numFolds=5)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "cvModel = crossval.fit(df)\n",
    "end_time = time.perf_counter()\n",
    "stage_times.append((\"CrossValidator\", end_time - start_time))\n",
    "\n",
    "# Print out the stage times\n",
    "for stage_name, timing in stage_times:\n",
    "    print(f\"{stage_name} took {timing:.8f} seconds\")\n",
    "\n",
    "# Model Evaluation (this is part of CrossValidator timing)\n",
    "predictions = cvModel.transform(df)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# Stop the session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
